{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include path to our library\n",
    "cwd = os.getcwd()\n",
    "dir_path = os.path.dirname(os.path.realpath(cwd))\n",
    "sys.path.append(dir_path)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path\n",
    "%cd $dir_path\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from core.utils.metrics import *\n",
    "from core.utils.utils import *\n",
    "from core.data.data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some configurations configurations of model and others\n",
    "configs = json.load(open('config_lstm.json', 'r'))\n",
    "output_path = configs['paths']['save_dir']\n",
    "output_logs = configs['paths']['log_dir']\n",
    "\n",
    "if os.path.isdir(output_path) == False:\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "if os.path.isdir(output_logs) == False:\n",
    "    os.mkdir(output_logs)        \n",
    "\n",
    "time_steps =  configs['model']['layers'][0]['input_timesteps']  # the number of points or hits\n",
    "num_features = configs['model']['layers'][0]['input_features']  # the number of features of each hits\n",
    "split_data = configs['data']['train_split']  # the number of features of each hits\n",
    "cylindrical = configs['data']['cylindrical']  # set to polar or cartesian coordenates\n",
    "#cylindrical = False\n",
    "normalise = configs['data']['normalise'] \n",
    "num_hits = configs['data']['num_hits']\n",
    "\n",
    "print('OK reading of json file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading path of data\n",
    "path = configs['data']['filename']\n",
    "#path = '/data/track-ml/eramia/dataset/phi025-025_eta025-025_train1_lasthit_20200219.csv'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(path, split_data, cylindrical, num_hits, KindNormalization.Zscore)\n",
    "# divimos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data.get_training_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "                                 n_features=num_features, normalise=False)\n",
    "\n",
    "\n",
    "#X_train = X_train.iloc[:,]\n",
    "#y_test = y_test[0:1000]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos as layers\n",
    "layer_1  = data.data.iloc[:, 0:3]\n",
    "layer_2  = data.data.iloc[:, 3:6]\n",
    "layer_3  = data.data.iloc[:, 6:9]\n",
    "layer_4  = data.data.iloc[:, 9:12]\n",
    "layer_5 = data.data.iloc[:, 12:15]\n",
    "layer_6 = data.data.iloc[:, 15:18]\n",
    "layer_7 = data.data.iloc[:, 18:21]\n",
    "layer_8 = data.data.iloc[:, 21:24]\n",
    "layer_9 = data.data.iloc[:, 24:27]\n",
    "layer_10 = data.data.iloc[:, 27:30]\n",
    "\n",
    "#layer_1  = data.data.iloc[0:5000, 0:3]\n",
    "#layer_2  = data.data.iloc[0:5000, 3:6]\n",
    "#layer_3  = data.data.iloc[0:5000, 6:9]\n",
    "#layer_4  = data.data.iloc[0:5000, 9:12]\n",
    "#layer_5 = data.data.iloc[0:5000, 12:15]\n",
    "#layer_6 = data.data.iloc[0:5000, 15:18]\n",
    "#layer_7 = data.data.iloc[0:5000, 18:21]\n",
    "#layer_8 = data.data.iloc[0:5000, 21:24]\n",
    "#layer_9 = data.data.iloc[0:5000, 24:27]\n",
    "#layer_10 = data.data.iloc[0:5000, 27:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#existe valores duplicados?\n",
    "layer_1_ = layer_1[layer_1.duplicated()]\n",
    "#layer_1_ existe valores repetido\n",
    "layer_2_ = layer_2[layer_2.duplicated()]\n",
    "#layer_2_  no existe\n",
    "layer_3_ = layer_3[layer_3.duplicated()]\n",
    "#layer_3_ no exisste\n",
    "layer_4_ = layer_4[layer_4.duplicated()]\n",
    "#layer_4_ # no existe\n",
    "\n",
    "layer_5_ = layer_5[layer_5.duplicated()]\n",
    "layer_6_ = layer_6[layer_6.duplicated()]\n",
    "#print(layer_6_)\n",
    "layer_5_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_5_.to_csv('duplicados_layer_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e1:2356 e2:1643 dist=0.0\n",
    "# e1:2523 e2:1497 dist=0.0\n",
    "# e1:2615 e2:1403 dist=0.0\n",
    "layer_5.iloc[1643,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_5.iloc[2356,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino valores duplicados\n",
    "layer_1_ = layer_1.drop_duplicates()\n",
    "print('new size :', layer_1_.count())\n",
    "\n",
    "layer_2_ = layer_2.drop_duplicates()\n",
    "print('new size :', layer_2_.count())\n",
    "\n",
    "layer_3_ = layer_3.drop_duplicates()\n",
    "print('new size :', layer_3_.count())\n",
    "\n",
    "layer_4_ = layer_4.drop_duplicates()\n",
    "print('new size :', layer_4_.count())\n",
    "\n",
    "layer_5_ = layer_5.drop_duplicates()\n",
    "print('new size :', layer_5_.count())\n",
    "\n",
    "layer_6_ = layer_6.drop_duplicates()\n",
    "print('new size :', layer_6_.count())\n",
    "\n",
    "layer_7_ = layer_7.drop_duplicates()\n",
    "print('new size :', layer_7_.count())\n",
    "\n",
    "layer_8_ = layer_8.drop_duplicates()\n",
    "print('new size :', layer_8_.count())\n",
    "\n",
    "layer_9_ = layer_9.drop_duplicates()\n",
    "print('new size :', layer_9_.count())\n",
    "\n",
    "layer_10_ = layer_10.drop_duplicates()\n",
    "print('new size :', layer_10_.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntamos todas as camadas\n",
    "sensor = data_true = np.concatenate([layer_1_, layer_2_, layer_3_, layer_4_ ,\n",
    "                                     layer_5_, layer_6_, layer_7_, layer_8_,\n",
    "                                     layer_9_, layer_10_], axis = 0)\n",
    "sensor = pd.DataFrame(sensor, columns=['x','y', 'z'])\n",
    "\n",
    "sensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos a minima distancia por Camada ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionamos que data set se normalizamos ou não\n",
    "#matrix = StandardScaler().fit_transform(layer_5_)\n",
    "#dataset = pd.DataFrame(layer_5_, columns=['x','y', 'z'])\n",
    "\n",
    "matrix = layer_5.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# Por camada\n",
    "\n",
    "max_dist = 1000\n",
    "seed = 0\n",
    "total = len(matrix)\n",
    "visited = []\n",
    "visited.append(seed)\n",
    "temp = {}\n",
    "counter = 0\n",
    "print('total ', total)\n",
    "print('processing...')\n",
    "shortest_point = {}\n",
    "all_distances = []\n",
    "for i in range(0, total):\n",
    "   \n",
    "    point = np.reshape(matrix[i], (1, 3))\n",
    "    matrix = np.delete(matrix, i, axis=0)\n",
    "    distances = distance.cdist(matrix, point, 'euclidean')  \n",
    "    min_dist = np.min(distances)\n",
    "    idx = np.argmin(distances)\n",
    "    matrix = np.insert(matrix, i, point[0], axis=0) \n",
    "    all_distances.append([np.mean(distances), np.min(distances), np.max(distances)])\n",
    "    \n",
    "    if min_dist <= max_dist:\n",
    "        max_dist = min_dist\n",
    "        shortest_point[i] = idx #matrix[idx].tolist()\n",
    "\n",
    "for key, value in shortest_point.items():\n",
    "    e1 = matrix[key].tolist()\n",
    "    e2 = matrix[value].tolist()\n",
    "    print(' e1:%s e2:%s dist=%s' % (key, value, calculate_distances_vec(e1,e2)))\n",
    "    #print(item)\n",
    "print(min_dist)\n",
    "print(shortest_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimimos a media, minima e maxima distancia\n",
    "sorted(all_distances)\n",
    "#print(len(all_distances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quaeis sao os hits de menor distancia?\n",
    "for key, value in shortest_point.items():\n",
    "    e1 = matrix[key].tolist()\n",
    "    e2 = matrix[value].tolist()\n",
    "    print(' e1:%s \\n e2:%s' % (e1, e2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontramos os Clusteres de acordo as distancias anteriores ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionamos que data set\n",
    "#dataset = StandardScaler().fit_transform(layer_5_)\n",
    "#dataset = pd.DataFrame(dataset, columns=['x','y', 'z'])\n",
    "\n",
    "layer_5_.columns = ['x','y', 'z']\n",
    "dataset = layer_5_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#model = DBSCAN(algorithm='auto', eps=0.15, min_samples=5) --layer 5\n",
    "model = DBSCAN(algorithm='auto', eps=5, min_samples=4)\n",
    "model.fit(dataset)\n",
    "#model.fit(layer_5_)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.labels_\n",
    "print(labels)\n",
    "print(set(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pontos ruido -1\n",
    "noise = list(labels).count(-1)\n",
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.DataFrame(labels, columns=['label']).label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero de clusteres\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = np.zeros_like(labels, dtype=bool)\n",
    "cores\n",
    "print(len(cores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core_sample_indices_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores[model.core_sample_indices_] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotamos todas as camadas en 2D\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.scatter(sensor.x, sensor.y, s=3)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "#plt.title('Detector layers(5000 tracks ~ 49900 hits)')\n",
    "plt.title('Detector layers')\n",
    "plt.savefig('detector.pdf')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotamos so uma camada\n",
    "fig, ax = plt.subplots(figsize=(14,12))\n",
    "ax.scatter(dataset.x, dataset.y,marker='o', c=labels)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotamos so uma camada\n",
    "fig, ax = plt.subplots(figsize=(14,12))\n",
    "ax.scatter(layer_5_.x, layer_5_.y, c=cores)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotamos os cluster de acordo a configurção\n",
    "X = layer_5_\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,12))\n",
    "\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    # all classes\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & cores]\n",
    "    plt.plot(xy.iloc[:, 0], xy.iloc[:, 1], 'o', c=tuple(col),\n",
    "             markersize=3)\n",
    "\n",
    "    xy = X[class_member_mask & ~cores]\n",
    "    plt.plot(xy.iloc[:, 0], xy.iloc[:, 1], 'o', c=tuple(col),\n",
    "               markersize=6)\n",
    "#markeredgecolor='k',\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# plotamos todas as camadas em 3d \n",
    "fig = go.Figure(data=[go.Scatter3d(x=sensor.x,\n",
    "                                   y=sensor.y,\n",
    "                                   z=sensor.z,\n",
    "                                   mode='markers',\n",
    "                                   marker=dict(\n",
    "                                        size=2.5,\n",
    "                                        #color=labels,                # set color to an array/list of desired values\n",
    "                                        colorscale='Jet',   # choose a colorscale\n",
    "                                        opacity=0.8\n",
    "                                    )\n",
    "                                  )])\n",
    "\n",
    "\n",
    "#fig.show()\n",
    "fig.write_html('sensor_labels.html', auto_open=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = (==5)\n",
    "#print(len(res))\n",
    "#print(len(labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each in np.linspace(0, 1, len(unique_labels)):\n",
    "for each in range(0, len(unique_labels)):\n",
    "    print(each)\n",
    "    #colors = matplotlib.colors.colorConverter.to_rgb(plt.cm.Spectral(each))\n",
    "    colors = 'rgb'+str(colors)\n",
    "    print(colors)\n",
    "\n",
    "colors = plt.cm.Spectral(labels.astype(float) / n_clusters)\n",
    "#print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficamos so por camada\n",
    "import matplotlib.pyplot as plt\n",
    "colors  =[]\n",
    "\n",
    "#matplotlib.colors.colorConverter.to_rgb()\n",
    "#for each in np.linspace(0, 1, len(unique_labels)):\n",
    "for each in len(unique_labels):\n",
    "    \n",
    "    colors = matplotlib.colors.colorConverter.to_rgb(plt.cm.Spectral(each/n_clusters))\n",
    "    colors = 'rgb'+str(colors)\n",
    "    print(colors)\n",
    "    \n",
    "X = layer_5_\n",
    "\n",
    "unique_labels = set(labels)\n",
    "\n",
    "\n",
    "clusters = []\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    print(col)\n",
    "    print(tuple(col))\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        #col = [0, 0, 0, 1]\n",
    "        col = [1.0, 'rgb(0,0,255)']\n",
    "\n",
    "    # all classes\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & cores]\n",
    "  \n",
    "    cluster = go.Scatter3d(x=xy.iloc[:, 0],\n",
    "                           y=xy.iloc[:, 1],\n",
    "                           z=xy.iloc[:, 2],\n",
    "                           mode='markers',\n",
    "                           marker=dict(\n",
    "                                size=3,\n",
    "                                color=col,       # set color to an array/list of desired values\n",
    "                                #colorscale=col,   # choose a colorscale\n",
    "                                opacity=0.8 \n",
    "                            )\n",
    "                          )\n",
    "    \n",
    "    clusters.append(cluster)\n",
    "\n",
    "    xy = X[class_member_mask & ~cores]\n",
    "\n",
    "    cluster = go.Scatter3d(x=xy.iloc[:, 0],\n",
    "                           y=xy.iloc[:, 1],\n",
    "                           z=xy.iloc[:, 2],\n",
    "                           mode='markers',\n",
    "                           marker=dict(\n",
    "                                size=2,\n",
    "                                color=tuple(col),       # set color to an array/list of desired values\n",
    "                                #colorscale=tuple(col),   # choose a colorscale\n",
    "                                opacity=1 \n",
    "                            )\n",
    "                          )\n",
    "    #clusters.append(cluster)\n",
    "    \n",
    "fig = go.Figure(data = clusters)\n",
    "\n",
    "#fig.show()\n",
    "fig.write_html('sensor_labels.html', auto_open=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=layer_5_.x,\n",
    "                                   y=layer_5_.y,\n",
    "                                   z=layer_5_.z,\n",
    "                                   mode='markers',\n",
    "                                   marker=dict(\n",
    "                                        size=2,\n",
    "                                        color=cores,\n",
    "                                        # set color to an array/list of desired values\n",
    "                                        #color='smoker',   # choose a colorscale\n",
    "                                        colorscale='Jet',\n",
    "                                        #showscale=True,\n",
    "                                        #opacity=0.8\n",
    "                                        #colorscale = [\n",
    "                                        #    [0., 'rgba(0,0,0, 1)'],\n",
    "                                        #    [1., 'rgba(255, 225, 255, 1)']]                                       \n",
    "                                    )\n",
    "                                  )])\n",
    "\n",
    "\n",
    "#fig.show()\n",
    "#fig.write_html('layer_labels.html', auto_open=True)  \n",
    "fig.write_html('layer_cores.html', auto_open=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=layer_5_.x,\n",
    "                                   y=layer_5_.y,\n",
    "                                   z=layer_5_.z,\n",
    "                                   mode='markers',\n",
    "                                   marker=dict(\n",
    "                                        size=2,\n",
    "                                        color=labels,\n",
    "                                        colorscale='Jet',\n",
    "                                    \n",
    "                                    )\n",
    "                                  )])\n",
    "\n",
    "\n",
    "#fig.show()\n",
    "#fig.write_html('layer_labels.html', auto_open=True)  \n",
    "fig.write_html('layer_labels.html', auto_open=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24,18))\n",
    "ax.scatter(layer_5.x, layer_5.y , c=sample_cores)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.title('Outlier Detection')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "ax.scatter(X_train.iloc[:,0], X_train.iloc[:,1], c=sample_cores )\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.title('Outlier Detection')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
